---
title: 分布式理论 
date: 2020-4-10 18:18:59
tags:
 - 分布式
categories:
 - 分布式
---

### 分布式理论

我们了解的数据库的 ACID 四大特性，已经无法满足我们分布式事务，这个时候又有一些新的大佬提出一些新的理论。

<!--more-->

#### CAP

CAP 定理，又被叫作布鲁尔定理。对于设计分布式系统(不仅仅是分布式事务)的架构师来说，CAP 就是你的入门理论。

- C (一致性)：对某个指定的客户端来说，读操作能返回写操作。

  对于数据分布在不同节点上的数据来说，如果在某个节点更新了数据，那么在其他节点如果都能读取到这个数据，那么就称为强一致，如果有某个节点没有读取到，那就是分布式不一致。

- A (可用性)：非故障的节点在合理的时间内返回合理的响应(不是错误和超时的响应)。可用性的两个关键一个是合理的时间，一个是合理的响应。

  合理的时间指的是请求不能被阻塞，应该在合理的时间给出返回。合理的响应指的是系统应该明确返回结果并且结果是正确的，这里的正确指的是比如应该返回 50，而不是返回 40。

- P (分区容错性)：当出现网络分区后，系统能够继续工作。打个比方，这里集群有多台机器，有台机器网络出现了问题，但是这个集群仍然可以正常工作。

熟悉 CAP 的人都知道，三者不能共有，如果感兴趣可以搜索 CAP 的证明，在分布式系统中，网络无法 100% 可靠，分区其实是一个必然现象。

如果我们选择了 CA 而放弃了 P，那么当发生分区现象时，为了保证一致性，这个时候必须拒绝请求，但是 A 又不允许，所以分布式系统理论上不可能选择 CA 架构，只能选择 CP 或者 AP 架构。

对于 CP 来说，放弃可用性，追求一致性和分区容错性，我们的 ZooKeeper 其实就是追求的强一致。

对于 AP 来说，放弃一致性(这里说的一致性是强一致性)，追求分区容错性和可用性，这是很多分布式系统设计时的选择，后面的 BASE 也是根据 AP 来扩展。

顺便一提，CAP 理论中是忽略网络延迟，也就是当事务提交时，从节点 A 复制到节点 B 没有延迟，但是在现实中这个是明显不可能的，所以总会有一定的时间是不一致。

同时 CAP 中选择两个，比如你选择了 CP，并不是叫你放弃 A。因为 P 出现的概率实在是太小了，大部分的时间你仍然需要保证 CA。

就算分区出现了你也要为后来的 A 做准备，比如通过一些日志的手段，是其他机器回复至可用。

| 组 合 | 分析结果                                                     |
| ----- | ------------------------------------------------------------ |
| CA    | 满足原子和可用，放弃分区容错。说白了，就是一个整体的应用。   |
| CP    | 满足原子和分区容错，也就是说，要放弃可用。当系统被分区，为了保证原子性，必须放弃可用性，让服务停用。 |
| AP    | 满足可用性和分区容错，当出现分区，同时为了保证可用性，必须让节点继续对外服务，这样必然导致失去原子性。 |

**能不能解决 3 选 2 的问题**

难道真的没有办法解决这个问题吗？

CAP 理论已经提出了 13 年，也许可以做些改变。

仔细想想，分区是百分之百出现的吗？如果不出现分区，那么就能够同时满足 CAP。如果出现了分区，可以根据策略进行调整。比如 C 不必使用那么强的一致性，可以先将数据存起来，稍后再更新，实现所谓的 “最终一致性”。

这个思路又是一个庞大的问题，同时也引出了第二个理论 Base 理论

#### BASE

BASE 是 Basically Available(基本可用)、Soft state(软状态)和 Eventually consistent (最终一致性)三个短语的缩写，是对 CAP 中 AP 的一个扩展。

1. 基本可用：分布式系统在出现故障时，允许损失部分可用功能，保证核心功能可用。

   假设系统，出现了不可预知的故障，但还是能用，相比较正常的系统而言：

   - 响应时间上的损失：正常情况下的搜索引擎 0.5 秒即返回给用户结果，而**基本可用**的搜索引擎可以在 1 秒作用返回结果。
   - 功能上的损失：在一个电商网站上，正常情况下，用户可以顺利完成每一笔订单，但是到了大促期间，为了保护购物系统的稳定性，部分消费者可能会被引导到一个降级页面。

2. 软状态：允许系统中存在中间状态，这个状态不影响系统可用性，这里指的是 CAP 中的不一致。

   相对于原子性而言，要求多个节点的数据副本都是一致的，这是一种 “硬状态”。

   软状态指的是：允许系统中的数据存在中间状态，并认为该状态不影响系统的整体可用性，即允许系统在多个不同节点的数据副本存在数据延时。

3. 最终一致：最终一致是指经过一段时间后，所有节点数据都将会达到一致。

   在实际工程实践中，**最终一致性分为 5 种：**

   **1. 因果一致性（Causal consistency）**

   指的是：如果节点 A 在更新完某个数据后通知了节点 B，那么节点 B 之后对该数据的访问和修改都是基于 A 更新后的值。于此同时，和节点 A 无因果关系的节点 C 的数据访问则没有这样的限制。

   **2. 读己之所写（Read your writes）**

   这种就很简单了，节点 A 更新一个数据后，它自身总是能访问到自身更新过的最新值，而不会看到旧值。其实也算一种因果一致性。

   **3. 会话一致性（Session consistency）**

   会话一致性将对系统数据的访问过程框定在了一个会话当中：系统能保证在同一个有效的会话中实现 “读己之所写” 的一致性，也就是说，执行更新操作之后，客户端能够在同一个会话中始终读取到该数据项的最新值。

   **4. 单调读一致性（Monotonic read consistency）**

   单调读一致性是指如果一个节点从系统中读取出一个数据项的某个值后，那么系统对于该节点后续的任何数据访问都不应该返回更旧的值。

   **5. 单调写一致性（Monotonic write consistency）**

   指一个系统要能够保证来自同一个节点的写操作被顺序的执行。

   然而，在实际的实践中，这 5 种系统往往会结合使用，以构建一个具有最终一致性的分布式系统。实际上，不只是分布式系统使用最终一致性，关系型数据库在某个功能上，也是使用最终一致性的，比如备份，数据库的复制过程是需要时间的，这个复制过程中，业务读取到的值就是旧的。当然，最终还是达成了数据一致性。这也算是一个最终一致性的经典案例。

BASE 解决了 CAP 中理论没有网络延迟，在 BASE 中用软状态和最终一致，保证了延迟后的一致性。

BASE 和 ACID 是相反的，它完全不同于 ACID 的强一致性模型，而是通过牺牲强一致性来获得可用性，并允许数据在一段时间内是不一致的，但最终达到一致状态。

为了解决分布式一致性问题，产生了一系列一致性协议和算法。其中比较著名的有：二阶段提交协议（2PC）、三阶段提交协议（3PC）、Paxos 算法、Raft 算法等。

### 一致性协议

为了使系统尽量能够达到 CAP，于是有了 BASE 协议，而 BASE 协议是在可用性和一致性之间做的取舍和妥协。

人们往往需要在系统的可用性和数据一致性之间反复的权衡。于是呢，就产生我们标题中的一致性协议，而且还不止一个呢。

为了解决分布式问题，涌现了很多经典的算法和协议，最著名的就是二阶段提交协议，三阶段提交协议，Paxos 算法。

#### 两阶段提交

Two-phase Commit（2PC）：保证一个事务跨越多个节点时保持 ACID 特性；

两类节点：协调者（Coordinator）和参与者（Participants），协调者只有一个，参与者可以有多个。

过程：

1. 准备阶段：协调者询问参与者事务是否执行成功；

   1. 事务询问
   协调者向所有的参与者询问，是否准备好了执行事务，并开始等待各参与者的响应。
   2. 执行事务
   各参与者节点执行事务操作，并将 Undo 和 Redo 信息记入事务日志中
   3. 各参与者向协调者反馈事务询问的响应
   如果参与者成功执行了事务操作，那么就反馈给协调者 Yes 响应，表示事务可以执行；如果参与者没有成功执行事务，就返回 No 给协调者，表示事务不可以执行。

   从上面可以感觉到，这个一个 所谓的 “投票阶段”，什么意思呢？所有的节点都投票决定是否执行事务操作。

2. 提交阶段：如果事务在每个参与者上都执行成功，协调者发送通知让参与者提交事务；否则，协调者发送通知让参与者回滚事务。

   在阶段二中，会根据阶段一的投票结果执行 2 种操作：执行事务提交，中断事务。

   **执行事务提交步骤如下：**

   1. 发送提交请求：协调者向所有参与者发出 commit 请求。
   2. 事务提交：参与者收到 commit 请求后，会正式执行事务提交操作，并在完成提交之后释放整个事务执行期间占用的事务资源。
   3. 反馈事务提交结果：参与者在完成事务提交之后，向协调者发送 Ack 信息。
   4. 协调者接收到所有参与者反馈的 Ack 信息后，完成事务。

   **中断事务步骤如下：**

   1. 发送回滚请求：协调者向所有参与者发出 Rollback 请求。
   2. 事务回滚：参与者接收到 Rollback 请求后，会利用其在阶段一种记录的 Undo 信息来执行事务回滚操作，并在完成回滚之后释放在整个事务执行期间占用的资源。
   3. 反馈事务回滚结果：参与者在完成事务回滚之后，想协调者发送 Ack 信息。
   4. 中断事务：协调者接收到所有参与者反馈的 Ack 信息后，完成事务中断。

   从上面的逻辑可以看出，二阶段提交就做了2个事情：投票，执行。

   > 核心是对每个事务都采用先尝试后提交的处理方式，因此也可以将二阶段提交看成一个强一致性的算法。

![YGIlZV.png](https://s1.ax1x.com/2020/05/11/YGIlZV.png)

需要注意的是，在准备阶段，参与者执行了事务，但是还未提交。只有在提交阶段接收到协调者发来的通知后，才进行提交或者回滚。

**优点**：原理简单，实现方便

**缺点**：同步阻塞，单点问题，数据不一致，过于保守

1. 同步阻塞：

   在二阶段提交的过程中，所有的节点都在等待其他节点的响应，无法进行其他操作。这种同步阻塞极大的限制了分布式系统的性能。

2. 单点问题：

   协调者在整个二阶段提交过程中很重要，如果协调者在提交阶段出现问题，那么整个流程将无法运转，更重要的是：其他参与者将会处于一直锁定事务资源的状态中，而无法继续完成事务操作。

3. 数据不一致：

   假设当协调者向所有的参与者发送 commti 请求之后，发生了局部网络异常或者是协调者在尚未发送完所有 commit 请求之前自身发生了崩溃，导致最终只有部分参与者收到了 commit 请求。这将导致严重的数据不一致问题。

4. 过于保守：

   如果在二阶段提交的提交询问阶段中，参与者出现故障而导致协调者始终无法获取到所有参与者的响应信息的化，这时协调者只能依靠其自身的超时机制来判断是否需要中断事务，显然，这种策略过于保守。换句话说，**二阶段提交协议没有设计较为完善的容错机制，任意一个节点是失败都会导致整个事务的失败**

**存在问题**：

- 参与者发生故障。解决方案：可以给事务设置一个超时时间，如果某个参与者一直不响应，那么认为事务执行失败。
- 协调者发生故障。解决方案：将操作日志同步到备用协调者，让备用协调者接替后续工作。

#### 三阶段提交

 2PC 理论，也就是两阶段提交，二阶段提交原理简单，实现方便，但是缺点则是同步阻塞，单点问题，数据不一致，过于保守。

而为了弥补二阶段提交的缺点，研究者们在他的基础上，提出了三阶段提交。

3PC，全称 “three phase commit”，是 2PC 的改进版，其将 2PC 的 “提交事务请求” 过程一分为二。

3PC 将阶段一 "提交事务请求" 分成了2部分，总共形成了 3 个部分：

1. CanCommit

   1. 事务询问：协调者向所有的参与者发送一个包含事务内容的 canCommit 请求，询问是否可以执行事务提交操作，并开始等待各参与者的响应。
   2. 各参与者向协调者反馈事务询问的响应：参与者接收来自协调者的 canCommit 请求，如果参与者认为自己可以顺利执行事务，就返回 Yes，否则反馈 No 响应。

2. PreCommit

   协调者在得到所有参与者的响应之后，会根据结果执行2种操作：执行事务预提交，或者中断事务。

   1. 执行事务预提交分为 3 个步骤：

   - 发送预提交请求：协调者向所有参与者节点发出 preCommit 的请求，并进入 prepared 状态。
   - 事务预提交：参与者受到 preCommit 请求后，会执行事务操作，对应 2PC 中的 “执行事务”，也会 Undo 和 Redo 信息记录到事务日志中。
   - 各参与者向协调者反馈事务执行的结果：如果参与者成功执行了事务，就反馈 Ack 响应，同时等待指令：提交（commit） 或终止（abor）。

   2. 中断事务也分为2个步骤：

   - 发送中断请求：协调者向所有参与者节点发出 abort 请求 。
   - 中断事务：参与者如果收到 abort 请求或者超时了，都会中断事务。

3. do Commit

   该阶段做真正的提交，同样也会出现两种情况：

   1. 执行提交

   - 发送提交请求：进入这一阶段，如果协调者正常工作，并且接收到了所有协调者的 Ack 响应，那么协调者将从 “预提交” 状态变为 “提交” 状态，并向所有的参与者发送 doCommit 请求 。
   - 事务提交：参与者收到 doCommit 请求后，会正式执行事务提交操作，并在完成之后释放在整个事务执行期间占用的事务资源。
   - 反馈事务提交结果：参与者完成事务提交后，向协调者发送 Ack 消息。
   - 完成事务：协调者接收到所有参与者反馈的 Ack 消息后，完成事务。

   2. 中断事务

   假设有任何参与者反馈了 no 响应，或者超时了，就中断事务。

   - 发送中断请求：协调者向所有的参与者节点发送 abort 请求。
   - 事务回滚：参与者接收到 abort 请求后，会利用其在二阶段记录的 undo 信息来执行事务回滚操作，并在完成回滚之后释放整个事务执行期间占用的资源。
   - 反馈事务回滚结果：参与者在完成事务回滚之后，想协调者发送 Ack 消息。
   - 中断事务：协调者接收到所有的 Ack 消息后，中断事务。

![YGI2QA.png](https://s1.ax1x.com/2020/05/11/YGI2QA.png)

注意：一旦进入阶段三，可能会出现 2 种故障：

1. 协调者出现问题
2. 协调者和参与者之间的网络故障

一段出现了任一一种情况，最终都会导致参与者无法收到 doCommit 请求或者 abort 请求，针对这种情况，参与者都会在等待超时之后，继续进行事务提交。

**优点**：相比较 2PC，最大的优点是减少了参与者的阻塞范围（第一个阶段是不阻塞的），并且能够在单点故障后继续达成一致（2PC 在提交阶段会出现此问题，而 3PC 会根据协调者的状态进行回滚或者提交）。

**缺点**：如果参与者收到了 preCommit 消息后，出现了网络分区，那么参与者等待超时后，都会进行事务的提交，这必然会出现事务不一致的问题。

#### Paxos协议

![YGomFO.png](https://s1.ax1x.com/2020/05/11/YGomFO.png)

分布式系统中的节点通信存在两种模型：**[共享内存](https://zh.wikipedia.org/wiki/共享内存)**（Shared memory）和**[消息传递](https://zh.wikipedia.org/w/index.php?title=消息传递&action=edit&redlink=1)**（Messages passing）。

基于消息传递通信模型的分布式系统，不可避免的会发生以下错误：进程可能会慢、被杀死或者重启，消息可能会延迟、丢失、重复，在基础Paxos场景中，先不考虑可能出现消息篡改即[拜占庭错误](https://zh.wikipedia.org/wiki/拜占庭将军问题)的情况。

Paxos算法解决的问题正是分布式一致性问题，即一个分布式系统中的各个进程如何就某个值（决议）达成一致。

Paxos算法运行在允许宕机故障的异步系统中，不要求可靠的消息传递，可容忍消息丢失、延迟、乱序以及重复。它利用大多数 (Majority) 机制保证了2F+1的容错能力，即2F+1个节点的系统最多允许F个节点同时出现故障。

一个或多个提议进程 (Proposer) 可以发起提案 (Proposal)，Paxos算法使所有提案中的某一个提案，在所有进程中达成一致。系统中的多数派同时认可该提案，即达成了一致。最多只针对一个确定的提案达成一致。

Paxos将系统中的角色分为提议者 (Proposer)，决策者 (Acceptor)，和最终决策学习者 (Learner):

- **Proposer**: 提出提案 (Proposal)。Proposal信息包括提案编号 (Proposal ID) 和提议的值 (Value)。
- **Acceptor**：参与决策，回应Proposers的提案。收到Proposal后可以接受提案，若Proposal获得多数Acceptors的接受，则称该Proposal被批准。
- **Learner**：不参与决策，从Proposers/Acceptors学习最新达成一致的提案（Value）。

在多副本状态机中，每个副本同时具有Proposer、Acceptor、Learner三种角色。

![YGwfQH.png](https://s1.ax1x.com/2020/05/11/YGwfQH.png)

Paxos算法通过一个决议分为两个阶段（Learn阶段之前决议已经形成）：

1. 第一阶段：Prepare阶段。Proposer向Acceptors发出Prepare请求，Acceptors针对收到的Prepare请求进行Promise承诺。
2. 第二阶段：Accept阶段。Proposer收到多数Acceptors承诺的Promise后，向Acceptors发出Propose请求，Acceptors针对收到的Propose请求进行Accept处理。
3. 第三阶段：Learn阶段。Proposer在收到多数Acceptors的Accept之后，标志着本次Accept成功，决议形成，将形成的决议发送给所有Learners。

Paxos算法流程中的每条消息描述如下：

- **Prepare**: Proposer生成全局唯一且递增的Proposal ID (可使用时间戳加Server ID)，向所有Acceptors发送Prepare请求，这里无需携带提案内容，只携带Proposal ID即可。
- **Promise**: Acceptors收到Prepare请求后，做出“两个承诺，一个应答”。

两个承诺：

1. 不再接受Proposal ID小于等于（注意：这里是<= ）当前请求的Prepare请求。

2. 不再接受Proposal ID小于（注意：这里是< ）当前请求的Propose请求。

一个应答：

不违背以前作出的承诺下，回复已经Accept过的提案中Proposal ID最大的那个提案的Value和Proposal ID，没有则返回空值。

- **Propose**: Proposer 收到多数Acceptors的Promise应答后，从应答中选择Proposal ID最大的提案的Value，作为本次要发起的提案。如果所有应答的提案Value均为空值，则可以自己随意决定提案Value。然后携带当前Proposal ID，向所有Acceptors发送Propose请求。
- **Accept**: Acceptor收到Propose请求后，在不违背自己之前作出的承诺下，接受并持久化当前Proposal ID和提案Value。
- **Learn**: Proposer收到多数Acceptors的Accept后，决议形成，将形成的决议发送给所有Learners。

Paxos算法伪代码描述如下：

![YG0pT0.png](https://s1.ax1x.com/2020/05/11/YG0pT0.png)

1. 获取一个Proposal ID n，为了保证Proposal ID唯一，可采用时间戳+Server ID生成；
2. Proposer向所有Acceptors广播Prepare(n)请求；
3. Acceptor比较n和minProposal，如果n>minProposal，minProposal=n，并且将 acceptedProposal 和 acceptedValue 返回；
4. Proposer接收到过半数回复后，如果发现有acceptedValue返回，将所有回复中acceptedProposal最大的acceptedValue作为本次提案的value，否则可以任意决定本次提案的value；
5. 到这里可以进入第二阶段，广播Accept (n,value) 到所有节点；
6. Acceptor比较n和minProposal，如果n>=minProposal，则acceptedProposal=minProposal=n，acceptedValue=value，本地持久化后，返回；否则，返回minProposal。
7. 提议者接收到过半数请求后，如果发现有返回值result >n，表示有更新的提议，跳转到1；否则value达成一致。

图解：<https://www.cnblogs.com/stateis0/p/9062130.html>

#### Raft协议

Raft 也是一个一致性算法，和 Paxos 目标相同。但他还有另一个名字：易于理解的一致性算法。

首先说什么是 Raft 算法：**Raft 是一种为了管理复制日志的一致性算法。**

什么是一致性呢？
Raft 的论文这么说的：一致性算法允许一组机器像一个整体一样工作，即使其中一些机器出现故障也能够继续工作下去。

这里的`一致性`针对分布式系统。

什么是管理日志呢？
一致性算法是从复制状态机的背景下提出的，复制状态机通常都是`基于复制日志`实现的，这个日志可以理解为一个比喻，相当于一个指令。

关于状态机的描述：

> 多个节点上，从相同的初始状态开始，执行相同的一串命令，产生相同的最终状态。实际上，与其说是一致，其实可以泛化为分布式的两个节点状态存在某种约束。
> 复制状态机通常都是基于复制日志实现的，**保证复制日志相同就是一致性算法的工作了。**
> 典型应用就是一个独立的的复制状态机去管理领导选举和存储配置信息并且在领导人宕机的情况下也要存活下来。比如 Chubby 和 ZooKeeper。

对于 Raft 更重要的应该是 `易于理解`。从 Raft 的论文题目就可以看出：`In Search of an Understandable Consensus Algorithm (Extended Version)`。这里的易于理解是相对于 Paxos 的，在他的论文中，和 Paxos 做了大量针对 `易于理解` 的对比和统计测试。

为了提升可理解性，Raft 将一致性算法分解成了几个关键模块，例如领导人选举、日志复制和安全性。

而和一致性最相关的就是前面 2 个模块：领导人选举和日志复制。

##### 领导人选举

Raft 通过选举一个高贵的领导人，然后给予他全部的管理复制日志的责任来实现一致性。

而每个 server 都可能会在 3 个身份之间切换：

- 领导者
- 候选者
- 跟随者

而影响他们身份变化的则是 `选举`。
当所有服务器初始化的时候，都是 `跟随者`，这个时候需要一个 `领导者`，所有人都变成 `候选者`，直到有人成功当选 `领导者`。

角色轮换如下图：

![YG7oFK.png](https://s1.ax1x.com/2020/05/11/YG7oFK.png)

而领导者也有宕机的时候，宕机后引发新的 `选举`，所以，整个集群在选举和正常运行之间切换，具体如下图：

![YG7jeI.png](https://s1.ax1x.com/2020/05/11/YG7jeI.png)

从上图可以看出，选举和正常运行之间切换，但请注意， 上图中的 term 3 有一个地方，后面没有跟着 `正常运行` 阶段，为什么呢?

答：当一次选举失败（比如正巧每个人都投了自己），就执行一次 `加时赛`，每个 Server 会在一个随机的时间里重新投票，这样就能保证不冲突了。所以，当 term 3 选举失败，等了几十毫秒，执行 term 4 选举，并成功选举出领导人。

接着，领导者周期性的向所有跟随者发送心跳包来维持自己的权威。如果一个跟随者在一段时间里没有接收到任何消息，也就是选举超时，那么他就会认为系统中没有可用的领导者,并且发起选举以选出新的领导者。

要开始一次选举过程，跟随者先要增加自己的当前任期号并且**转换到候选人状态**。然后请求其他服务器`为自己投票`。那么会产生 3 种结果：

a. 自己成功当选
b. 其他的服务器成为领导者
c. 僵住，没有任何一个人成为领导者

注意：

1. 每一个 server 最多在一个任期内投出一张选票（有任期号约束），先到先得。
2. 要求最多只能有一个人赢得选票。
3. 一旦成功，立即成为领导人，然后广播所有服务器停止投票阻止新得领导产生。

僵住怎么办？ Raft 通过使用随机选举超时时间（例如 150 - 300 毫秒）的方法将服务器打散投票。每个候选人在僵住的时候会随机从一个时间开始重新选举。

##### 日志复制

一旦一个领导人被选举出来，他就开始为客户端提供服务。

客户端发送日志给领导者，随后领导者将日志复制到其他的服务器。如果跟随者故障，领导者将会尝试重试。直到所有的跟随者都成功存储了所有日志。

下图表示了当一个客户端发送一个日志给领导者，随后领导者复制给跟随者的整个过程。

![YGHEmn.png](https://s1.ax1x.com/2020/05/11/YGHEmn.png)

4 个步骤：

1. 客户端提交
2. 复制数据到所有跟随者
3. 跟随者回复 `确认收到`
4. 领导者回复客户端和所有跟随者 `确认提交`。

可以看到，直到第四步骤，整个事务才会达成。中间任何一个步骤发生故障，都不会影响日志一致性。

图解：<https://www.jianshu.com/p/8e4bbe7e276c>

### 参考

1. [图解Paxos](https://www.jianshu.com/p/3e4163ae6fb3)
2. [分布式一致性协议介绍（Paxos、Raft）](https://www.cnblogs.com/zhang-qc/p/8688258.html)
3. [如何浅显易懂地解说 Paxos 的算法？](https://www.zhihu.com/question/19787937)
4. [图解 Paxos 一致性协议](http://blog.xiaohansong.com/2016/09/30/Paxos/)
5. [分布式系列文章——Paxos算法原理与推导](http://www.cnblogs.com/linbingdong/p/6253479.html)
6. [Paxos算法 维基百科，自由的百科全书](https://zh.wikipedia.org/wiki/Paxos算法)
7. [Paxos Made Simple【翻译】](https://wenku.baidu.com/view/bf8e118fa0116c175f0e4853.html?from=search)
8. [The Part-Time Parliament(Paxos算法中文翻译)](https://wenku.baidu.com/view/87276e1dfad6195f312ba6d7.html)
9. [Raft 官网](https://raft.github.io/)
10. [Raft 原理动画 (推荐看看)][http://thesecretlivesofdata.com/raft/](http://thesecretlivesofdata.com/raft/)